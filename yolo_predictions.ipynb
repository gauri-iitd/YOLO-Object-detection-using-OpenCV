{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903edfab-3308-4fab-8703-3c37d2e2fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68798db1-575d-4fcf-b7f0-100e71985f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7a633b-3e83-4c67-95c1-989ba0075a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'car', 'chair', 'bottle', 'pottedplant', 'bird', 'dog', 'sofa', 'bicycle', 'horse', 'boat', 'motorbike', 'cat', 'tvmonitor', 'cow', 'sheep', 'aeroplane', 'train', 'diningtable', 'bus']\n"
     ]
    }
   ],
   "source": [
    "#Load YAML file\n",
    "with open ('data.yaml',mode='r') as f:\n",
    "    data_yaml=yaml.load(f,Loader=SafeLoader)\n",
    "labels=data_yaml['names']\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff0129e-9544-448a-9df6-2a813516ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load YOLO model\n",
    "yolo=cv2.dnn.readNetFromONNX('./Model/weights/best.onnx')\n",
    "yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3db1ebc-9254-4b2a-a1e9-89ab380ed380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the image\n",
    "img=cv2.imread('./street_image.jpg')\n",
    "image=img.copy()\n",
    "# cv2.imshow('image',image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "#get the yolo prediction from the image\n",
    "row,col,d=image.shape\n",
    "max_rc=max(row,col)\n",
    "input_image=np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n",
    "input_image[0:row,0:col]=image\n",
    "cv2.imshow('input_image',input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "INPUT_WH_YOLO=640\n",
    "blob=cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)\n",
    "yolo.setInput(blob)\n",
    "preds=yolo.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4141a6a7-dcb7-4133-80de-7c3568ecf5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[6.07138348e+00 6.15279007e+00 1.08319111e+01 ... 1.29076531e-02\n",
      "   5.78450924e-03 9.82694514e-03]\n",
      "  [1.30390301e+01 6.48160362e+00 2.32015114e+01 ... 2.16921289e-02\n",
      "   5.64418267e-03 8.36158171e-03]\n",
      "  [1.52809315e+01 6.24085426e+00 2.61480808e+01 ... 1.51709989e-02\n",
      "   4.76285163e-03 7.24944379e-03]\n",
      "  ...\n",
      "  [5.58898621e+02 5.99633240e+02 1.67139221e+02 ... 2.81131845e-02\n",
      "   9.16726142e-03 6.83718873e-03]\n",
      "  [5.81945251e+02 6.01006165e+02 1.20045036e+02 ... 3.50637585e-02\n",
      "   1.10786110e-02 9.82030388e-03]\n",
      "  [6.10856140e+02 6.07646729e+02 1.24473045e+02 ... 5.73381595e-02\n",
      "   1.69466659e-02 1.61697194e-02]]]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31bc23f-020c-409f-a0c5-fb302932588f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 25200, 25)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a9cd17e-1897-4139-bdf4-fbab0f4fc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non maximum seperation filter\n",
    "#step1: filter data based on confidence (0.4) and probability score (0.25)\n",
    "detections=preds[0]\n",
    "boxes=[]\n",
    "confidences=[] \n",
    "classes=[]\n",
    "#width and height of the image (input_image)\n",
    "image_w,image_h=input_image.shape[:2]\n",
    "x_factor=image_w/INPUT_WH_YOLO\n",
    "y_factor=image_h/INPUT_WH_YOLO\n",
    "for i in range (len(detections)):\n",
    "    row=detections[i]\n",
    "    confidence=row[4]\n",
    "    if(confidence>0.4):\n",
    "        class_score=row[5:].max()\n",
    "        class_id=row[5:].argmax()\n",
    "        if(class_score>0.25):\n",
    "            cx,cy,w,h=row[0:4]\n",
    "            #construct bounding from four values\n",
    "            #left,top,width and height\n",
    "            left=int((cx-0.5*w)*x_factor)\n",
    "            top=int((cy-0.5*h)*y_factor)\n",
    "            width=int(w*x_factor)\n",
    "            height=int(h*y_factor)\n",
    "            box=np.array([left,top,width,height])\n",
    "            #append values into the list\n",
    "            confidences.append(confidence)\n",
    "            boxes.append(box)\n",
    "            classes.append(class_id)\n",
    "#clean\n",
    "boxes_np=np.array(boxes).tolist()\n",
    "confidences_np=np.array(confidences).tolist()\n",
    "#NMS\n",
    "index=cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7749579-aacc-424d-9776-0b4574aeb22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101, 252, 114, 112, 146, 150, 125, 168,  39,  57, 158, 211,  72,\n",
       "       135, 132, 138, 201, 251,  60, 250, 140, 238])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20143d42-1c72-4e4a-a6a6-89eb58ff5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car:0.9353675246238708%\n",
      "bus:0.9196479320526123%\n",
      "person:0.8978628516197205%\n",
      "person:0.8681949973106384%\n",
      "person:0.8499895334243774%\n",
      "person:0.8430705666542053%\n",
      "car:0.8088557124137878%\n",
      "person:0.799999475479126%\n",
      "car:0.7979838848114014%\n",
      "person:0.7772835493087769%\n",
      "person:0.7758364081382751%\n",
      "car:0.7727779746055603%\n",
      "car:0.7583931088447571%\n",
      "car:0.7336118817329407%\n",
      "car:0.7284842133522034%\n",
      "car:0.726668119430542%\n",
      "car:0.6645348072052002%\n",
      "car:0.5873633027076721%\n",
      "person:0.4725692570209503%\n",
      "car:0.45943138003349304%\n",
      "person:0.4281356632709503%\n",
      "car:0.4267643392086029%\n"
     ]
    }
   ],
   "source": [
    "#draw the bounding box\n",
    "for ind in index:\n",
    "    #extract the bounding box\n",
    "    x,y,w,h=boxes_np[ind]\n",
    "    bb_conf=confidences_np[ind]\n",
    "    classes_id=classes[ind]\n",
    "    class_name=labels[classes_id]\n",
    "    text=f'{class_name}:{bb_conf}%'\n",
    "    print(text)\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0))\n",
    "    cv2.rectangle(image,(x,y-30),(x+w,y),(255,255,255),-1)\n",
    "    cv2.putText(image,text,(x,y-10),cv2.FONT_HERSHEY_PLAIN,0.7,(0,0,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3441c6b8-9903-4050-8782-0ccd825c75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('original',img)\n",
    "cv2.imshow('yolo_prediction',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d31e3-b1dd-436c-a6f8-d1343d2d6df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
